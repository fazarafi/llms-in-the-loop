{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82c87367cd70bae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b5cff764f1fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:20.830557Z",
     "start_time": "2024-02-21T13:42:19.886094Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerativeModel, \n",
    "    HarmCategory, \n",
    "    HarmBlockThreshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1421b033bd3e9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:20.835174Z",
     "start_time": "2024-02-21T13:42:20.832421Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 50\n",
    "REPEAT_ANNOTATION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1762ae7983e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:20.839728Z",
     "start_time": "2024-02-21T13:42:20.836451Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specifying path to the necessary files and folders\n",
    "PATH_TO_SRC = os.path.abspath('../../../')\n",
    "\n",
    "# Where to get annotation examples for the prompt\n",
    "ANNOTATION_EXAMPLES_PATH = os.path.join(PATH_TO_SRC, 'src/query/ner_examples_all_languages.json')\n",
    "CONFIG_PATH = os.path.join(PATH_TO_SRC, \"settings/config.yml\")\n",
    "# Folder to save annotations\n",
    "RESULTS_PATH = os.path.join(PATH_TO_SRC, 'data/foundation_model_selection/gemini-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74700731e1e661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:20.845684Z",
     "start_time": "2024-02-21T13:42:20.841953Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def extend_sys_path(path):\n",
    "    if path not in sys.path:\n",
    "        # Append the path to sys.path\n",
    "        sys.path.append(path)\n",
    "    try:\n",
    "        # Execute code inside the 'with' statement\n",
    "        yield\n",
    "    finally:\n",
    "        # Remove the path from sys.path\n",
    "        if path in sys.path:\n",
    "            sys.path.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c61c1ee320d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:23.117266Z",
     "start_time": "2024-02-21T13:42:20.846949Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temporarily add module_path and import functions\n",
    "with extend_sys_path(PATH_TO_SRC):\n",
    "    from src.data.sample import sample_for_model_selection\n",
    "    from src.query.query_gpt import add_annotation_examples\n",
    "    from src.query.prompts import MAIN_PROMPT\n",
    "    from src.utils.utils import calculate_consistency_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d974f088fb0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:23.167371Z",
     "start_time": "2024-02-21T13:42:23.157739Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading config file\n",
    "config = yaml.safe_load(open(os.path.join(PATH_TO_SRC, \"settings/config.yml\")))\n",
    "\n",
    "# Load indx-to-label_name mapping\n",
    "label_mapping = config['label_mapping']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd033762153f338",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a6244de9b9133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:23.176530Z",
     "start_time": "2024-02-21T13:42:23.168988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ask_gemini_short(tokens, language, examples, user_prompt,\n",
    "                    temperature, model, system_prompt=None):\n",
    "\n",
    "    sentence = str(tokens)\n",
    "\n",
    "    if system_prompt is None:\n",
    "        system_prompt = f\"You are a named entity labelling expert in {language} language.\"\n",
    "\n",
    "    # Format user prompt\n",
    "    user_prompt = user_prompt.format(language=language, sentence=sentence, examples=examples)\n",
    "\n",
    "    # Save query params\n",
    "    json_query_params = {\n",
    "        'messages': [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                     {\"role\": \"user\", \"content\": user_prompt}],\n",
    "    }\n",
    "\n",
    "    str_query_params = json.dumps(json_query_params)\n",
    "\n",
    "    # Initialization of the model\n",
    "    vertexai.init()\n",
    "    gemini = GenerativeModel(model)\n",
    "\n",
    "    # Query the model\n",
    "    response = gemini.generate_content(\n",
    "        str_query_params,\n",
    "        generation_config={\n",
    "            \"temperature\": temperature\n",
    "        },\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Model answer\n",
    "    try:\n",
    "        return response.text\n",
    "    except:\n",
    "        print('#'*80)\n",
    "        print('Model didn\\'t generate any output.')\n",
    "        return \"{'output':[]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa85d12cd70e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:23.186082Z",
     "start_time": "2024-02-21T13:42:23.177907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeat_annotation(n_repeat=10, **ask_gemini_kwargs):\n",
    "    # Counters\n",
    "    no_json_counter = 0  # No json was provided by the model\n",
    "    incorrect_format_counter = 0  # Number of records parsed in the incorrect format \n",
    "\n",
    "    # Results\n",
    "    ner_tokens_arr = []\n",
    "\n",
    "    for i in tqdm(range(n_repeat)):\n",
    "        # Send request to a model\n",
    "        model_response = ask_gemini_short(**ask_gemini_kwargs)\n",
    "\n",
    "        # Handle rate limitation on Gemini API\n",
    "        # This is done by waiting for a second after each query\n",
    "        #time.sleep(1)\n",
    "\n",
    "        # # Extract json only\n",
    "        match = re.search(r'\\{(.*?)\\}', model_response)\n",
    "        if match:\n",
    "            content = match.group(0)\n",
    "            # Format output string to parse it as JSON\n",
    "            try:\n",
    "                ner_tags = json.loads(json.dumps(ast.literal_eval(content)))['output']\n",
    "                ner_tokens_arr.append(ner_tags)\n",
    "            except Exception as e:\n",
    "                print('#'*80)\n",
    "                print(e)\n",
    "                print(model_response)\n",
    "                incorrect_format_counter += 1\n",
    "                continue\n",
    "        else:\n",
    "            print('#'*80)\n",
    "            print('No json found in model\\'s response:', model_response)\n",
    "            no_json_counter += 1\n",
    "            continue\n",
    "\n",
    "    print(f'Number of model responses without json: {no_json_counter}')\n",
    "    print(f'Number of model responses with incorrect formatting: {incorrect_format_counter}')\n",
    "    return ner_tokens_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4fda68aff9f169",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Querying (fon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895a55c888052dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:23.196550Z",
     "start_time": "2024-02-21T13:42:23.189013Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LANGUAGE = 'fon'\n",
    "\n",
    "language_name = config['languages_names'][LANGUAGE]\n",
    "language_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efec4f26488052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:24.691666Z",
     "start_time": "2024-02-21T13:42:23.197944Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading dataset from HuggingFace\n",
    "data = load_dataset(config['dataset'], LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426c585204a23c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:25.862967Z",
     "start_time": "2024-02-21T13:42:24.693455Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_subset = sample_for_model_selection(data, label_mapping, n_samples=SAMPLE_SIZE, verbose=True)\n",
    "sampled_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eec295929973e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:42:25.868750Z",
     "start_time": "2024-02-21T13:42:25.864383Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ask_gemini_params = {\n",
    "    'language': language_name,\n",
    "    'examples': add_annotation_examples(ANNOTATION_EXAMPLES_PATH, language_name),\n",
    "    'user_prompt': MAIN_PROMPT,\n",
    "    'model': 'gemini-1.0-pro-vision-001',\n",
    "    'temperature': config['foundation_model']['temperature']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4694ef68d47e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:28.339265Z",
     "start_time": "2024-02-21T13:42:25.870159Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemini_annotations = {}\n",
    "consistency_scores = []\n",
    "\n",
    "# Measure how much time it takes to get all inferences\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for i, record in enumerate(sampled_subset):\n",
    "    print(f'\\nSample {i+1}:')\n",
    "    \n",
    "    try: \n",
    "        # Extract ground truth\n",
    "        ground_truth_labels = [label_mapping[t] for t in record['ner_tags']]\n",
    "        \n",
    "        # Extract tokens from current record\n",
    "        ask_gemini_params['tokens'] = record['tokens']\n",
    "\n",
    "        # Query the model\n",
    "        new_labels_gemini = repeat_annotation(n_repeat=REPEAT_ANNOTATION, **ask_gemini_params)\n",
    "        \n",
    "        # Save annotations\n",
    "        gemini_annotations[f'record_{i}'] = {}\n",
    "        gemini_annotations[f'record_{i}']['pred'] = new_labels_gemini\n",
    "        gemini_annotations[f'record_{i}']['true'] = ground_truth_labels\n",
    "        gemini_annotations[f'record_{i}']['tokens'] = record['tokens']\n",
    "        \n",
    "        # Calculate consistency score\n",
    "        consistency = calculate_consistency_score(new_labels_gemini, ground_truth_labels)\n",
    "        gemini_annotations[f'record_{i}']['consistency'] = consistency\n",
    "        consistency_scores.append(consistency)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time: ', end - start, 's')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall consistency is calculated by averaging individual scores\n",
    "gemini_annotations['overall_consistency'] = np.mean(consistency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86264f40fe901bd9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of samples that model didn't generate any output for them: \", consistency_scores.count(0))\n",
    "\n",
    "print(\"Overall consistency on all samples: \", gemini_annotations['overall_consistency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf0f83750ef744",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'{LANGUAGE}.json'), 'w') as file:\n",
    "    json.dump(gemini_annotations, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
