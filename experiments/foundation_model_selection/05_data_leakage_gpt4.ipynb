{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868423bcb2374ae9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup & Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb90216da6c2af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d828ce59705875e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:50.159685Z",
     "start_time": "2024-03-06T20:11:48.160091Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from contextlib import contextmanager\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import APIStatusError, RateLimitError, APIConnectionError\n",
    "import numpy as np\n",
    "import time\n",
    "from getpass import getpass\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "import regex as re\n",
    "from datasets.utils import disable_progress_bar\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1685e55b343405e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:50.180457Z",
     "start_time": "2024-03-06T20:11:50.178438Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gpt-4 -> GPT-4 cutoff 2021\n",
    "MODEL = 'gpt-4'\n",
    "# Testing leakage with 0 temperature for more deterministic results\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dec6a47899bc239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:50.184794Z",
     "start_time": "2024-03-06T20:11:50.181778Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specifying path to the necessary files and folders\n",
    "PATH_TO_SRC = os.path.abspath('../../../')\n",
    "CONFIG_PATH = os.path.join(PATH_TO_SRC, \"settings/config.yml\")\n",
    "RESULTS_PATH = os.path.join(PATH_TO_SRC, 'data/data_leakage', MODEL)\n",
    "\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.mkdir(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ae1c8d9f185a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:50.188254Z",
     "start_time": "2024-03-06T20:11:50.185580Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def extend_sys_path(path):\n",
    "    if path not in sys.path:\n",
    "        # Append the path to sys.path\n",
    "        sys.path.append(path)\n",
    "    try:\n",
    "        # Execute code inside the 'with' statement\n",
    "        yield\n",
    "    finally:\n",
    "        # Remove the path from sys.path\n",
    "        if path in sys.path:\n",
    "            sys.path.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b675c14ed9f7362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:53.459783Z",
     "start_time": "2024-03-06T20:11:50.189134Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temporarily add module_path and import functions\n",
    "with extend_sys_path(PATH_TO_SRC):\n",
    "    from src.utils.utils import get_api_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a86e3e85435e6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.525245Z",
     "start_time": "2024-03-06T20:11:53.461213Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init openai client\n",
    "openai_client = OpenAI(api_key=getpass(\"OPENAI API key:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4deb8673b460a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.529652Z",
     "start_time": "2024-03-06T20:11:57.526666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ASK_GPT_PARAMS = {\n",
    "    'openai_client': openai_client,\n",
    "    'model': MODEL,\n",
    "    'temperature': TEMPERATURE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6771b899197458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.551334Z",
     "start_time": "2024-03-06T20:11:57.530848Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading config file\n",
    "config = yaml.safe_load(open(os.path.join(PATH_TO_SRC, \"settings/config.yml\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8669e779ec7f9e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39768954e217f14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.558361Z",
     "start_time": "2024-03-06T20:11:57.554175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_from_dataset(dataset_dict, num_samples=10, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly samples a specified number of examples from each split \n",
    "    in a DatasetDict in a reproducible manner.\n",
    "    \"\"\"\n",
    "    # Set the numpy random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    sampled_dataset_dict = DatasetDict()\n",
    "\n",
    "    # Iterate over each split in the original DatasetDict\n",
    "    for split, dataset in dataset_dict.items():\n",
    "        # Generate a list of random indices with no replacement\n",
    "        indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "        # Select the samples corresponding to the generated indices\n",
    "        sampled_dataset = dataset.select(indices)\n",
    "\n",
    "        # Add the sampled dataset to the new DatasetDict\n",
    "        sampled_dataset_dict[split] = sampled_dataset\n",
    "\n",
    "    return sampled_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10a279876c9dcba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.563472Z",
     "start_time": "2024-03-06T20:11:57.559283Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ask_gpt(\n",
    "        user_prompt, \n",
    "        openai_client,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        model='gpt-4-0125-preview',\n",
    "        system_prompt=None):\n",
    "\n",
    "    if system_prompt is None:\n",
    "        system_prompt = \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "\n",
    "    # Save query params\n",
    "    query_params = {\n",
    "        'model': model,\n",
    "        'temperature': temperature,\n",
    "        'messages': [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                     {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        'max_tokens': max_tokens,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Query the model\n",
    "        response = openai_client.chat.completions.create(**query_params)\n",
    "        # Extract model answer\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "\n",
    "    except APIConnectionError as e:\n",
    "        raise Exception(f\"The server could not be reached: {e.__cause__}\")\n",
    "    except RateLimitError as e:\n",
    "        raise Exception(f\"A 429 status code was received: {e}\")\n",
    "    except APIStatusError as e:\n",
    "        raise Exception(f\"Non-200-range status code received: {e.status_code}, {e.response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10807fcfbec02247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.567878Z",
     "start_time": "2024-03-06T20:11:57.564370Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_guess_stats(answers, pattern):\n",
    "    \"\"\"\n",
    "    Computes the correct guess counts and percentages for each dictionary in answers based on a regex pattern.\n",
    "    \"\"\"\n",
    "    correct_guess_counts = []\n",
    "    correct_guess_percentages = []\n",
    "\n",
    "    for answer_dict in answers:\n",
    "        match_count = sum(answer_dict[key] for key in answer_dict if re.search(pattern, key))\n",
    "        num_records = sum(answer_dict.values())\n",
    "\n",
    "        correct_guess_counts.append(match_count)\n",
    "        correct_guess_percentages.append(match_count / num_records if num_records else 0)\n",
    "\n",
    "    mean_percentage = round(np.mean(correct_guess_percentages), 2)\n",
    "    std_deviation = round(np.std(correct_guess_percentages), 2)\n",
    "\n",
    "    return mean_percentage, std_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c5c35ed184778",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0895f8a2921afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.571119Z",
     "start_time": "2024-03-06T20:11:57.568783Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guided instruction for sentence continuation \n",
    "GUI_SENT = \"\"\"INSTRUCTION:\n",
    "You are provided with the FIRST PIECE of data sample tokens from the {split_name} split of the {dataset_name} dataset. Finish the SECOND PIECE of the sample tokens as EXACTLY appeared in the dataset. ONLY rely on the original form of the sample tokens in the dataset to finish the SECOND PIECE. Do not return labels, provide only tokens exactly as they appear in the dataset.\n",
    "\n",
    "FIRST PIECE:\n",
    "{sentence}\n",
    "\n",
    "SECOND PIECE:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94ab11c21b12476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.574373Z",
     "start_time": "2024-03-06T20:11:57.572083Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GPT-4 evaluation prompt\n",
    "ICL_EVAL = \"\"\"INSTRUCTION:\n",
    "You are provided with a piece of reference text and a piece of candidate text.\n",
    "The candidate text is a generated replica of the reference text.\n",
    "Your task is to determine if the candidate text is an exact or near-exact match of the reference text.\n",
    "Near-exact match candidates must match the reference candidates in terms of sentence structure, overlap, and contextual similarity.\n",
    "Respond only with 'Yes' or 'No'.\n",
    "---\n",
    "Example 1:\n",
    "REFERENCE TEXT:\n",
    "The cat waited at the top.\n",
    "CANDIDATE TEXT:\n",
    "The cat waited at the top.\n",
    "\n",
    "ANSWER: Yes (exact match)\n",
    "---\n",
    "Example 2:\n",
    "REFERENCE TEXT:\n",
    "'نيرو 2'\n",
    "CANDIDATE TEXT:\n",
    "'نيرو '\n",
    "\n",
    "ANSWER: Yes (near-exact match)\n",
    "---\n",
    "Example 3:\n",
    "REFERENCE TEXT:\n",
    "Japan) Suzuki 1:27.501\n",
    "CANDIDATE TEXT:\n",
    "JPN) Kawasaki 1:27.808\n",
    "\n",
    "ANSWER: Yes (near-exact match)\n",
    "---\n",
    "Example 4:\n",
    "REFERENCE TEXT:\n",
    "1996-08-22\n",
    "CANDIDATE TEXT:\n",
    "1996-08-26\n",
    "\n",
    "ANSWER: Yes (near-exact match)\n",
    "---\n",
    "Example 5:\n",
    "REFERENCE TEXT:\n",
    "{reference_text}\n",
    "CANDIDATE TEXT:\n",
    "{candidate_text}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fb69d465c6630",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Asking LLM about data sample source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c482f12caaaef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A few previous experiments have shown that a foundation model (currently we focus on GPT-4-Turbo) answers correctly name of the dataset for randomly chosen samples from old datasets. At the same time, it is not able to answer the source of the records from our NER dataset masakhaner2.\n",
    "\n",
    "We evaluate how well the model knows the source for the random data samples from a few famous datasets and our focus dataset masakhaner2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35ffb50d126e01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GPT-4-Turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c52a33ebc59cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CoNLL-2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8bf1d4f470c9663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:57.577130Z",
     "start_time": "2024-03-06T20:11:57.575219Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Identify the source NER dataset for this sample. Respond with the dataset name alone. {sentence}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1bf3dc9d5f4814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:58.960944Z",
     "start_time": "2024-03-06T20:11:57.577983Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abc668400214412ad37c465f1ade26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll = load_dataset(\"conll2003\")\n",
    "\n",
    "conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da0494b807d9d55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:06.639746Z",
     "start_time": "2024-03-06T20:11:58.962459Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a82101dd6c417388d918d3a93933e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'train': {'11394': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2164': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '7803': \"sorry, but the provided sample doesn't contain enough information to identify a specific named entity recognition (ner) dataset.\",\n",
       "   '321': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '5407': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '12294': 'conll-2003\\n',\n",
       "   '7545': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '11242': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '974': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '9011': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.'},\n",
       "  'validation': {'1058': \"sorry, but the provided text doesn't specify a particular named entity recognition (ner) dataset.\",\n",
       "   '2570': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2599': \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\",\n",
       "   '1246': 'this question does not provide enough information to identify a specific ner (named entity recognition) dataset. the sentence could potentially be part of many different ner datasets.',\n",
       "   '430': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '140': \"sorry, but the provided information doesn't seem to be enough to identify a specific named entity recognition (ner) dataset. could you provide more context or details?\",\n",
       "   '1012': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '2185': \"this sample does not come from a specific named ner (named entity recognition) dataset. it appears to be a list of rugby players from new zealand, but without further context, it's not possible to identify a specific dataset.\",\n",
       "   '3151': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1528': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.'},\n",
       "  'test': {'944': 'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset. ner datasets are typically large collections of annotated sentences used for training machine learning models. this single sentence could potentially be part of many different ner datasets, or none at all.',\n",
       "   '1588': 'this prompt does not provide information about a specific ner (named entity recognition) dataset.',\n",
       "   '4': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '744': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '906': 'this information is not sufficient to identify a specific ner (named entity recognition) dataset.',\n",
       "   '2230': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '494': \"sorry, but the provided information doesn't seem to be directly related to a specific named entity recognition (ner) dataset.\",\n",
       "   '80': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2878': \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\",\n",
       "   '1216': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.'}},\n",
       " {'train': {'272': 'the provided sample does not directly indicate a specific named entity recognition (ner) dataset.',\n",
       "   '4300': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '11531': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1060': 'the provided text does not specify a source ner (named entity recognition) dataset.',\n",
       "   '588': 'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '13957': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2797': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '6161': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '11661': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '8453': \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\"},\n",
       "  'validation': {'2385': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '1393': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '3236': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2364': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2291': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2922': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1959': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1404': 'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1957': \"sorry, but the provided information doesn't seem to be directly associated with a specific named entity recognition (ner) dataset.\",\n",
       "   '272': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.'},\n",
       "  'test': {'3429': \"sorry, but the provided information doesn't seem to be specific to any known named entity recognition (ner) dataset. it appears to be related to sports statistics, possibly football, but it's not enough to identify a specific dataset.\",\n",
       "   '2461': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '892': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '2045': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '763': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '1655': \"sorry, but i can't provide the information you're looking for. as an ai, i don't have the ability to access external databases or datasets directly, including named entity recognition (ner) datasets. i generate responses based on a mixture of licensed data, data created by human trainers, and publicly available data. i don't have the ability to access or retrieve personal data unless it has been shared with me in the course of our conversation. i am designed to respect user privacy and confidentiality.\",\n",
       "   '2406': \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\",\n",
       "   '2143': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '553': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '3052': \"sorry, but the provided sample doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\"}},\n",
       " {'train': {'11597': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '12836': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '6988': 'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '3608': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '3053': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '10571': 'the provided sample does not specify a source ner (named entity recognition) dataset.',\n",
       "   '3017': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '8005': 'sorry, but the provided information is not sufficient to identify the source named entity recognition (ner) dataset.',\n",
       "   '4342': 'the provided sample does not contain any specific named entity recognition (ner) data.',\n",
       "   '4071': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.'},\n",
       "  'validation': {'338': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '767': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '662': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2751': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '3075': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '404': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '650': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2408': \"sorry, but the provided sample doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\",\n",
       "   '2813': \"sorry, but the provided information doesn't seem to be associated with a specific named entity recognition (ner) dataset.\",\n",
       "   '2535': 'this sample does not provide information about a specific ner (named entity recognition) dataset.'},\n",
       "  'test': {'845': \"sorry, but the provided text doesn't specify a particular named entity recognition (ner) dataset. it's a sentence likely related to football, mentioning juventus, a football club, and some player names, but it doesn't provide information about a specific ner dataset.\",\n",
       "   '2784': 'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '535': \"sorry, but the provided sample doesn't contain enough information to identify a specific named entity recognition (ner) dataset.\",\n",
       "   '2238': \"sorry, but as an ai model, i don't have the ability to access external databases or datasets directly. i generate responses based on a mixture of licensed data, data created by human trainers, and publicly available data. i don't have the ability to identify the specific dataset a given sample comes from.\",\n",
       "   '2581': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.',\n",
       "   '44': \"sorry, but the provided text doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\",\n",
       "   '1696': 'this question does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '131': \"sorry, but the provided sample doesn't seem to be directly from a specific named entity recognition (ner) dataset. it appears to be cricket match statistics, but without additional context, it's not possible to identify a specific dataset.\",\n",
       "   '2301': 'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.',\n",
       "   '2419': 'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.'}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_experiment = 3\n",
    "conll_answers = []\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    # Dictionary to save current experiments results\n",
    "    experiment_answers = {}\n",
    "\n",
    "    # Random sampling of N records from each split in the dataset\n",
    "    conll_samples = sample_from_dataset(conll, num_samples=10, seed=experiment_i)\n",
    "    \n",
    "    # Iterate over each data split and its corresponding samples\n",
    "    for data_split, samples in conll_samples.items():\n",
    "        # Store answers for each split\n",
    "        experiment_answers[data_split] = {}\n",
    "    \n",
    "        # For each sample in the current data split -> ask source\n",
    "        for i, (id, tokens) in enumerate(zip(samples['id'], samples['tokens'])):\n",
    "            # Format prompt with current data sample\n",
    "            query = user_prompt.format(sentence=str(tokens))\n",
    "            experiment_answers[data_split][id] = ask_gpt(query, **ASK_GPT_PARAMS).lower()\n",
    "\n",
    "    conll_answers.append(experiment_answers)\n",
    "\n",
    "conll_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd8597768e28f4d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:06.644667Z",
     "start_time": "2024-03-06T20:14:06.641082Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'CoNLL-2003_sample_source.json'), 'w') as file:\n",
    "    json.dump(conll_answers, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aafb27398bcc350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:06.650622Z",
     "start_time": "2024-03-06T20:14:06.646102Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate number of times the data sample source was guessed correctly\n",
    "conll_answers = json.load(open(os.path.join(RESULTS_PATH, f'CoNLL-2003_sample_source.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b41225a4510bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:06.669637Z",
     "start_time": "2024-03-06T20:14:06.651763Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd57741e8cd415789ab6d951a85d923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.': 4,\n",
       "  'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.': 5,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific named entity recognition (ner) dataset.\": 1,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.': 6,\n",
       "  'conll-2003\\n': 1,\n",
       "  'the provided sample does not specify a source ner (named entity recognition) dataset.': 3,\n",
       "  \"sorry, but the provided text doesn't specify a particular named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\": 2,\n",
       "  'this question does not provide enough information to identify a specific ner (named entity recognition) dataset. the sentence could potentially be part of many different ner datasets.': 1,\n",
       "  \"sorry, but the provided information doesn't seem to be enough to identify a specific named entity recognition (ner) dataset. could you provide more context or details?\": 1,\n",
       "  \"this sample does not come from a specific named ner (named entity recognition) dataset. it appears to be a list of rugby players from new zealand, but without further context, it's not possible to identify a specific dataset.\": 1,\n",
       "  'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset. ner datasets are typically large collections of annotated sentences used for training machine learning models. this single sentence could potentially be part of many different ner datasets, or none at all.': 1,\n",
       "  'this prompt does not provide information about a specific ner (named entity recognition) dataset.': 1,\n",
       "  'this information is not sufficient to identify a specific ner (named entity recognition) dataset.': 1,\n",
       "  \"sorry, but the provided information doesn't seem to be directly related to a specific named entity recognition (ner) dataset.\": 1},\n",
       " {'the provided sample does not directly indicate a specific named entity recognition (ner) dataset.': 1,\n",
       "  'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.': 3,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.': 10,\n",
       "  'the provided text does not specify a source ner (named entity recognition) dataset.': 1,\n",
       "  'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset.': 2,\n",
       "  'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.': 3,\n",
       "  'the provided sample does not specify a source ner (named entity recognition) dataset.': 4,\n",
       "  \"sorry, but the provided information doesn't specify a particular named entity recognition (ner) dataset.\": 2,\n",
       "  \"sorry, but the provided information doesn't seem to be directly associated with a specific named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but the provided information doesn't seem to be specific to any known named entity recognition (ner) dataset. it appears to be related to sports statistics, possibly football, but it's not enough to identify a specific dataset.\": 1,\n",
       "  \"sorry, but i can't provide the information you're looking for. as an ai, i don't have the ability to access external databases or datasets directly, including named entity recognition (ner) datasets. i generate responses based on a mixture of licensed data, data created by human trainers, and publicly available data. i don't have the ability to access or retrieve personal data unless it has been shared with me in the course of our conversation. i am designed to respect user privacy and confidentiality.\": 1,\n",
       "  \"sorry, but the provided sample doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\": 1},\n",
       " {'the provided sample does not specify a source ner (named entity recognition) dataset.': 3,\n",
       "  'this prompt does not provide enough information to identify a specific named entity recognition (ner) dataset.': 3,\n",
       "  'the provided sample does not contain enough information to identify a specific named entity recognition (ner) dataset.': 1,\n",
       "  'this sample does not provide enough information to identify a specific named entity recognition (ner) dataset.': 4,\n",
       "  'sorry, but the provided information is not sufficient to identify the source named entity recognition (ner) dataset.': 1,\n",
       "  'the provided sample does not contain any specific named entity recognition (ner) data.': 1,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific named entity recognition (ner) dataset.': 8,\n",
       "  \"sorry, but the provided sample doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but the provided information doesn't seem to be associated with a specific named entity recognition (ner) dataset.\": 1,\n",
       "  'this sample does not provide information about a specific ner (named entity recognition) dataset.': 1,\n",
       "  \"sorry, but the provided text doesn't specify a particular named entity recognition (ner) dataset. it's a sentence likely related to football, mentioning juventus, a football club, and some player names, but it doesn't provide information about a specific ner dataset.\": 1,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but as an ai model, i don't have the ability to access external databases or datasets directly. i generate responses based on a mixture of licensed data, data created by human trainers, and publicly available data. i don't have the ability to identify the specific dataset a given sample comes from.\": 1,\n",
       "  \"sorry, but the provided text doesn't contain enough specific information to identify a particular named entity recognition (ner) dataset.\": 1,\n",
       "  'this question does not provide enough information to identify a specific named entity recognition (ner) dataset.': 1,\n",
       "  \"sorry, but the provided sample doesn't seem to be directly from a specific named entity recognition (ner) dataset. it appears to be cricket match statistics, but without additional context, it's not possible to identify a specific dataset.\": 1}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of times each dataset name is predicted\n",
    "conll_counts = []\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    conll_answers_list = []\n",
    "\n",
    "    experiment_answers = conll_answers[experiment_i]\n",
    "    for split, samples in experiment_answers.items():\n",
    "        conll_answers_list += list(samples.values())\n",
    "\n",
    "    # Append current experiment answers\n",
    "    conll_counts.append(dict(Counter(conll_answers_list)))\n",
    "\n",
    "conll_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d816797509c789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:06.676044Z",
     "start_time": "2024-03-06T20:14:06.670871Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.01\n",
      "Std: 0.02\n"
     ]
    }
   ],
   "source": [
    "mean, std = compute_guess_stats(answers=conll_counts, pattern=re.compile(r'conll.*03'))\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0165f345d15d26e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### WikiAnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287e664d323ed8b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "WikiAnn is a dataset for cross-lingual name tagging and linking based on Wikipedia articles in 295 languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9670c45064ab62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:07.181091Z",
     "start_time": "2024-03-06T20:14:06.677347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get languages from the dataset\n",
    "url = \"https://datasets-server.huggingface.co/splits?dataset=wikiann\"\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610288777e184477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:07.186019Z",
     "start_time": "2024-03-06T20:14:07.182206Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ace', 'af', 'als', 'am', 'an']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiann_languages = sorted(list({item['config'] for item in data['splits']}))\n",
    "wikiann_languages[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71bd7e55d4b8deee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:07.191521Z",
     "start_time": "2024-03-06T20:14:07.187334Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bh', 'et', 'sk'], dtype='<U12')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a list of random languages with no replacement\n",
    "np.random.seed(42)\n",
    "num_languages = 3\n",
    "\n",
    "sampled_languages = np.random.choice(wikiann_languages, size=num_languages, replace=False)\n",
    "sampled_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e56b9391ee8a4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "bh: Bihari languages. It's a group of languages spoken in the Bihar region of India, but \"bh\" is often used specifically to refer to Bhojpuri.\n",
    "et: Estonian. A Uralic language spoken primarily in Estonia.\n",
    "sk: Slovak. A West Slavic language spoken in Slovakia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be94750916a60c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:07.195165Z",
     "start_time": "2024-03-06T20:14:07.192789Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_id(example, idx):\n",
    "    example['id'] = idx\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f0afd9f2897b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:14:07.198529Z",
     "start_time": "2024-03-06T20:14:07.196260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Identify the source multilingual NER dataset for this sample. Respond with the dataset name alone. {sentence}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "958fa50139bee4d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.053652Z",
     "start_time": "2024-03-06T20:14:07.199462Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061d84da892c4208b22278ecd36062d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/ace (download: 33.75 KiB, generated: 98.64 KiB, post-processed: Unknown size, total: 132.39 KiB) to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.55 MiB, generated: 8.02 MiB, post-processed: Unknown size, total: 10.58 MiB) to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.81 MiB, generated: 8.98 MiB, post-processed: Unknown size, total: 11.79 MiB) to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 33.75 KiB, generated: 98.64 KiB, post-processed: Unknown size, total: 132.39 KiB) to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.55 MiB, generated: 8.02 MiB, post-processed: Unknown size, total: 10.58 MiB) to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.81 MiB, generated: 8.98 MiB, post-processed: Unknown size, total: 11.79 MiB) to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 33.75 KiB, generated: 98.64 KiB, post-processed: Unknown size, total: 132.39 KiB) to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c65ce95d64b276e7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.55 MiB, generated: 8.02 MiB, post-processed: Unknown size, total: 10.58 MiB) to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-abae0dbda02627e3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset None/ace (download: 2.81 MiB, generated: 8.98 MiB, post-processed: Unknown size, total: 11.79 MiB) to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-017d20d6290acf07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'bh': {208: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   188: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   12: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   221: 'wikiann',\n",
       "   239: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   136: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   230: 'wikiann',\n",
       "   206: 'wikiann',\n",
       "   52: 'wikiann',\n",
       "   108: 'wikiann'},\n",
       "  'et': {32940: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   9739: \"sorry, but i can't provide the answer you're looking for.\",\n",
       "   23365: \"sorry, but the provided sample doesn't seem to be directly linked to a specific multilingual named entity recognition (ner) dataset.\",\n",
       "   31332: 'wikiann',\n",
       "   34227: 'wikiann\\n',\n",
       "   441: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   28942: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   788: 'wikiann',\n",
       "   29813: \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   10314: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.'},\n",
       "  'sk': {12836: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   10913: 'wikiann',\n",
       "   4214: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   8198: \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample alone. the sample is in slovak language, but without more context or information, it's not possible to identify the specific dataset it comes from.\",\n",
       "   31403: 'wikiann\\n',\n",
       "   13917: \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   27440: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   11667: 'wikiann\\n',\n",
       "   29616: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   39864: 'wikiann'}},\n",
       " {'bh': {189: 'wikiann',\n",
       "   123: 'wikiann',\n",
       "   185: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   213: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   106: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   127: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   176: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\",\n",
       "   73: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   275: 'wikiann',\n",
       "   242: 'wikiann'},\n",
       "  'et': {25474: \"sorry, but i can't identify the source multilingual ner dataset from this sample without additional context or information.\",\n",
       "   19761: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   32740: 'wikiann',\n",
       "   34148: \"sorry, but i can't identify the source multilingual ner dataset from this sample without additional context or information.\",\n",
       "   5218: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   17371: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   11160: 'wikiann',\n",
       "   2445: 'wikiann',\n",
       "   27584: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   4545: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.'},\n",
       "  'sk': {3841: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   12898: 'wikiann',\n",
       "   15032: \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\",\n",
       "   36781: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   9201: 'wikiann\\n',\n",
       "   21288: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   37321: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   8600: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   33089: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   39511: 'wikiann'}},\n",
       " {'bh': {98: 'wikiann\\n',\n",
       "   259: 'wikiann',\n",
       "   184: 'wikiann\\n',\n",
       "   256: 'wikiann',\n",
       "   29: 'wikiann',\n",
       "   254: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   7: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   13: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.',\n",
       "   230: 'wikiann',\n",
       "   91: 'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.'},\n",
       "  'et': {32557: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   14168: \"sorry, but the provided text sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   21315: 'wikiann',\n",
       "   34768: 'wikiann',\n",
       "   33490: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   34404: \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual named entity recognition (ner) dataset.\",\n",
       "   23350: \"sorry, but i can't provide the exact source of this multilingual ner dataset based on the provided sample.\",\n",
       "   2999: 'wikiann',\n",
       "   3719: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   11340: 'wikiann'},\n",
       "  'sk': {2727: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   26907: 'wikiann\\n',\n",
       "   16283: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\",\n",
       "   31845: \"sorry, but i can't identify the source multilingual ner dataset from this sample alone.\",\n",
       "   19862: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   38929: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   8545: 'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.',\n",
       "   19447: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   27187: \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   5471: 'the provided sample does not contain enough information to identify a specific multilingual ner (named entity recognition) dataset.'}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_experiment = 3\n",
    "wikiann_answers = []\n",
    "\n",
    "# Disable datasets load_dataset progress bar\n",
    "disable_progress_bar()\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    experiment_answers = {}\n",
    "\n",
    "    for i, lan in enumerate(sampled_languages):\n",
    "        # Load wikiann split for each of the sampled languages\n",
    "        wikiann = load_dataset(\"wikiann\", data_dir=lan, \n",
    "                               download_mode=\"force_redownload\",\n",
    "                               verification_mode=\"no_checks\")\n",
    "    \n",
    "        # Concatenate train, test, and validation splits \n",
    "        wikiann = DatasetDict({\n",
    "            \"merged\": concatenate_datasets([wikiann['train'], wikiann['test'], wikiann['validation']])\n",
    "        })\n",
    "        # Add ids per records based on the index of the record\n",
    "        wikiann = wikiann.map(add_id, with_indices=True)\n",
    "        # Sample\n",
    "        wikiann_samples = sample_from_dataset(wikiann, 10, seed=experiment_i)['merged']\n",
    "\n",
    "        experiment_answers[lan] = {}\n",
    "        # Ask source for the sampled records\n",
    "        for id_, tokens in zip(wikiann_samples['id'], wikiann_samples['tokens']):\n",
    "            # Format prompt with current data sample\n",
    "            query = user_prompt.format(sentence=str(tokens))\n",
    "            experiment_answers[lan][id_] = ask_gpt(query, **ASK_GPT_PARAMS).lower()\n",
    "\n",
    "    wikiann_answers.append(experiment_answers)\n",
    "\n",
    "wikiann_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f1aae6ea64248a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.064084Z",
     "start_time": "2024-03-06T20:17:24.058808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'WikiAnn_sample_source.json'), 'w') as file:\n",
    "    json.dump(wikiann_answers, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f3180b5aa887d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.078294Z",
     "start_time": "2024-03-06T20:17:24.065310Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf0fc972ada4ed095c6eabff01b1c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{\"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 5,\n",
       "  'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.': 4,\n",
       "  'wikiann': 9,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.': 4,\n",
       "  \"sorry, but i can't provide the answer you're looking for.\": 1,\n",
       "  \"sorry, but the provided sample doesn't seem to be directly linked to a specific multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  'wikiann\\n': 3,\n",
       "  \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 2,\n",
       "  \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample alone. the sample is in slovak language, but without more context or information, it's not possible to identify the specific dataset it comes from.\": 1},\n",
       " {'wikiann': 9,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.': 7,\n",
       "  'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.': 5,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but i can't identify the source multilingual ner dataset from this sample without additional context or information.\": 2,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 4,\n",
       "  \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  'wikiann\\n': 1},\n",
       " {'wikiann\\n': 3,\n",
       "  'wikiann': 8,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 3,\n",
       "  'sorry, but the provided information is not sufficient to identify a specific multilingual ner (named entity recognition) dataset.': 8,\n",
       "  'sorry, but the provided information is not sufficient to identify the source multilingual ner (named entity recognition) dataset.': 2,\n",
       "  \"sorry, but the provided text sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but i can't provide the exact source of this multilingual ner dataset based on the provided sample.\": 1,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  \"sorry, but i can't identify the source multilingual ner dataset from this sample alone.\": 1,\n",
       "  'the provided sample does not contain enough information to identify a specific multilingual ner (named entity recognition) dataset.': 1}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate number of times the data sample source was guessed correctly\n",
    "wikiann_answers = json.load(open(os.path.join(RESULTS_PATH, f'WikiAnn_sample_source.json'), 'r'))\n",
    "\n",
    "# Count number of times each dataset name is predicted\n",
    "wikiann_counts = []\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    wikiann_answers_list = []\n",
    "\n",
    "    experiment_answers = wikiann_answers[experiment_i]\n",
    "    for split, samples in experiment_answers.items():\n",
    "        wikiann_answers_list += list(samples.values())\n",
    "\n",
    "    # Append current experiment answers\n",
    "    wikiann_counts.append(dict(Counter(wikiann_answers_list)))\n",
    "\n",
    "wikiann_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1db03e1aa9a3cdc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.083098Z",
     "start_time": "2024-03-06T20:17:24.079166Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.37\n",
      "Std: 0.03\n"
     ]
    }
   ],
   "source": [
    "mean, std = compute_guess_stats(answers=wikiann_counts, pattern=re.compile(r'(wikiann.*|xtreme)'))\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a633faef4411ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### masakhaner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f56fd31f81e2cc00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.087815Z",
     "start_time": "2024-03-06T20:17:24.084022Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'ewe', 'nya'], dtype='<U3')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Languages that were added to the second version of the masakhaner2\n",
    "masakhaner2_languages = ['bam', 'ewe', 'fon', 'twi', 'bbj', 'nya', 'tsn', 'sna', 'xho', 'zul']\n",
    "\n",
    "# Generate a list of random languages \n",
    "np.random.seed(42)\n",
    "num_languages = 3\n",
    "\n",
    "sampled_languages = np.random.choice(masakhaner2_languages, size=num_languages, replace=False)\n",
    "sampled_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a82663110a82a74e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:17:24.090574Z",
     "start_time": "2024-03-06T20:17:24.088647Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Identify the source multilingual NER dataset for this sample. Respond with the dataset name alone. {sentence}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8db58e29f93a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:33.206885Z",
     "start_time": "2024-03-06T20:17:24.091473Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70abb3f19f4947ac88989d6ebd88fa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/xho/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/nya/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/xho/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/nya/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/xho/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n",
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/nya/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'xho': {'3341': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '62': \"sorry, but i can't provide the exact source of this multilingual ner dataset based on the provided sample.\",\n",
       "   '811': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual named entity recognition (ner) dataset this sample is from.\",\n",
       "   '2602': 'masakhane ner\\n',\n",
       "   '4397': \"sorry, but i can't identify the source multilingual ner (named entity recognition) dataset from the provided sample. the sample appears to be in zulu, but without more context or specific identifiers, it's not possible to determine the exact dataset it comes from.\",\n",
       "   '1123': 'masakhane ner dataset',\n",
       "   '449': 'masakhane ner\\n',\n",
       "   '341': 'masakhane ner\\n',\n",
       "   '108': \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '2534': 'masakhane ner\\n'},\n",
       "  'ewe': {'472': \"i'm sorry, but without additional context or information, it's not possible to identify the specific source of a multilingual ner (named entity recognition) dataset from a single sentence or phrase.\",\n",
       "   '2086': 'masakhane ner\\n',\n",
       "   '985': 'masakhane ner\\n',\n",
       "   '125': 'masakhane ner\\n',\n",
       "   '2995': \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\",\n",
       "   '450': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\",\n",
       "   '584': \"i'm sorry, but without additional context, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\",\n",
       "   '2317': \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\",\n",
       "   '422': 'wikiann',\n",
       "   '2077': 'masakhane ner\\n'},\n",
       "  'nya': {'222': 'masakhane ner dataset',\n",
       "   '538': \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '575': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\",\n",
       "   '1603': \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset.\",\n",
       "   '2603': 'wikiann',\n",
       "   '199': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '1356': 'masakhane ner\\n',\n",
       "   '267': 'masakhane ner corpus',\n",
       "   '1216': \"i'm sorry, but it's not possible to identify the source multilingual ner dataset from this sample alone. the text appears to be in chichewa (a language spoken in malawi), but without further context or information, it's impossible to determine the specific dataset it comes from.\",\n",
       "   '3045': \"i'm sorry, but without additional context, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this text sample alone. the text appears to be in the chichewa language, but many datasets could potentially include this language.\"}},\n",
       " {'xho': {'3341': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '62': \"sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample.\",\n",
       "   '811': 'masakhane ner\\n',\n",
       "   '2602': 'masakhane ner\\n',\n",
       "   '4397': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '1123': 'masakhane ner dataset',\n",
       "   '449': 'masakhane ner\\n',\n",
       "   '341': 'masakhane ner\\n',\n",
       "   '108': \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample.\",\n",
       "   '2534': 'masakhane ner dataset'},\n",
       "  'ewe': {'472': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\",\n",
       "   '2086': 'masakhane ner dataset',\n",
       "   '985': 'masakhane ner\\n',\n",
       "   '125': 'masakhane ner\\n',\n",
       "   '2995': \"i'm sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample. the sample appears to be in a language that isn't commonly used in popular ner datasets, and without more context or information, it's challenging to identify the specific dataset.\",\n",
       "   '450': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\",\n",
       "   '584': 'winer',\n",
       "   '2317': \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\",\n",
       "   '422': \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from the provided sample.\",\n",
       "   '2077': 'masakhane ner\\n'},\n",
       "  'nya': {'222': 'masakhane ner dataset',\n",
       "   '538': \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this sample.\",\n",
       "   '575': 'masakhane ner dataset',\n",
       "   '1603': \"i'm sorry, but the provided text doesn't contain enough specific information to identify a particular multilingual named entity recognition (ner) dataset.\",\n",
       "   '2603': 'wikiann',\n",
       "   '199': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '1356': 'masakhane ner\\n',\n",
       "   '267': 'masakhane ner corpus',\n",
       "   '1216': \"i'm sorry, but the provided text doesn't seem to be a part of any well-known multilingual named entity recognition (ner) dataset. it appears to be a sentence or paragraph in chichewa, a language spoken in malawi. however, without more context or information, it's not possible to identify a specific dataset.\",\n",
       "   '3045': 'wikiann'}},\n",
       " {'xho': {'3341': 'masakhane ner\\n',\n",
       "   '62': \"sorry, but i can't provide the information you're looking for.\",\n",
       "   '811': \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample.\",\n",
       "   '2602': 'masakhane ner\\n',\n",
       "   '4397': \"sorry, but i can't identify the source multilingual ner dataset from the provided sample.\",\n",
       "   '1123': 'masakhane ner dataset',\n",
       "   '449': 'masakhane ner\\n',\n",
       "   '341': 'masakhane ner\\n',\n",
       "   '108': \"sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample.\",\n",
       "   '2534': 'masakhane ner\\n'},\n",
       "  'ewe': {'472': \"i'm sorry, but without additional context or information, it's not possible to identify the specific source of a multilingual ner (named entity recognition) dataset from a single sentence or phrase.\",\n",
       "   '2086': \"i'm sorry, but without additional context, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\",\n",
       "   '985': 'masakhane ner\\n',\n",
       "   '125': 'masakhane ner\\n',\n",
       "   '2995': \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\",\n",
       "   '450': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\",\n",
       "   '584': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\",\n",
       "   '2317': 'wikiann',\n",
       "   '422': \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from the provided sample.\",\n",
       "   '2077': 'masakhane ner\\n'},\n",
       "  'nya': {'222': 'masakhane ner dataset',\n",
       "   '538': \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset from which this sample is taken.\",\n",
       "   '575': 'masakhane ner dataset',\n",
       "   '1603': \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset.\",\n",
       "   '2603': \"i'm sorry, but the provided text doesn't seem to be a part of a well-known multilingual ner (named entity recognition) dataset. it's also important to note that without additional context or metadata, it's challenging to accurately identify the source dataset of a given text sample.\",\n",
       "   '199': \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\",\n",
       "   '1356': \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset from the provided sample alone.\",\n",
       "   '267': 'masakhane ner corpus',\n",
       "   '1216': \"i'm sorry, but it's not possible to identify the source multilingual ner (named entity recognition) dataset from this sample alone. the text appears to be in chichewa, a language spoken in malawi, but without more context or information, it's not possible to identify a specific dataset.\",\n",
       "   '3045': \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this text sample alone.\"}}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_experiment = 3\n",
    "masakhaner2_answers = []\n",
    "\n",
    "# Disable datasets load_dataset progress bar\n",
    "disable_progress_bar()\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    experiment_answers = {}\n",
    "\n",
    "    for i, lan in enumerate(sampled_languages):\n",
    "        # Load wikiann split for each of the sampled languages\n",
    "        masaknaner2 = load_dataset(config['dataset'], lan)\n",
    "\n",
    "        # Concatenate train, test, and validation splits \n",
    "        masaknaner2 = DatasetDict({\n",
    "            \"merged\": concatenate_datasets(\n",
    "                [masaknaner2['train'], masaknaner2['test'], masaknaner2['validation']])\n",
    "        })\n",
    "        # Sample\n",
    "        masaknaner2_samples = sample_from_dataset(masaknaner2, 10)['merged']\n",
    "\n",
    "        experiment_answers[lan] = {}\n",
    "        # Ask source for the sampled records\n",
    "        for id_, tokens in zip(masaknaner2_samples['id'], masaknaner2_samples['tokens']):\n",
    "            # Format prompt with current data sample\n",
    "            query = user_prompt.format(sentence=str(tokens))\n",
    "            experiment_answers[lan][id_] = ask_gpt(query, **ASK_GPT_PARAMS).lower()\n",
    "\n",
    "    masakhaner2_answers.append(experiment_answers)\n",
    "\n",
    "masakhaner2_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d4aa46f4e471a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:33.212446Z",
     "start_time": "2024-03-06T20:19:33.208513Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'masakhaner2_sample_source.json'), 'w') as file:\n",
    "    json.dump(masakhaner2_answers, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcb47e913b31d100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:33.228972Z",
     "start_time": "2024-03-06T20:19:33.213789Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcaac8011ab4370a79cee39794cb22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment #:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{\"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 2,\n",
       "  \"sorry, but i can't provide the exact source of this multilingual ner dataset based on the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual named entity recognition (ner) dataset this sample is from.\": 1,\n",
       "  'masakhane ner\\n': 9,\n",
       "  \"sorry, but i can't identify the source multilingual ner (named entity recognition) dataset from the provided sample. the sample appears to be in zulu, but without more context or specific identifiers, it's not possible to determine the exact dataset it comes from.\": 1,\n",
       "  'masakhane ner dataset': 2,\n",
       "  \"sorry, but the provided text doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 2,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific source of a multilingual ner (named entity recognition) dataset from a single sentence or phrase.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\": 2,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\": 2,\n",
       "  \"i'm sorry, but without additional context, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\": 1,\n",
       "  'wikiann': 2,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset.\": 1,\n",
       "  'masakhane ner corpus': 1,\n",
       "  \"i'm sorry, but it's not possible to identify the source multilingual ner dataset from this sample alone. the text appears to be in chichewa (a language spoken in malawi), but without further context or information, it's impossible to determine the specific dataset it comes from.\": 1,\n",
       "  \"i'm sorry, but without additional context, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this text sample alone. the text appears to be in the chichewa language, but many datasets could potentially include this language.\": 1},\n",
       " {\"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 3,\n",
       "  \"sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample.\": 1,\n",
       "  'masakhane ner\\n': 8,\n",
       "  'masakhane ner dataset': 5,\n",
       "  \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\": 1,\n",
       "  \"i'm sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample. the sample appears to be in a language that isn't commonly used in popular ner datasets, and without more context or information, it's challenging to identify the specific dataset.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\": 1,\n",
       "  'winer': 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this sample.\": 1,\n",
       "  \"i'm sorry, but the provided text doesn't contain enough specific information to identify a particular multilingual named entity recognition (ner) dataset.\": 1,\n",
       "  'wikiann': 2,\n",
       "  'masakhane ner corpus': 1,\n",
       "  \"i'm sorry, but the provided text doesn't seem to be a part of any well-known multilingual named entity recognition (ner) dataset. it appears to be a sentence or paragraph in chichewa, a language spoken in malawi. however, without more context or information, it's not possible to identify a specific dataset.\": 1},\n",
       " {'masakhane ner\\n': 8,\n",
       "  \"sorry, but i can't provide the information you're looking for.\": 1,\n",
       "  \"sorry, but i can't provide the exact source of this specific multilingual ner (named entity recognition) dataset based on the provided sample.\": 1,\n",
       "  \"sorry, but i can't identify the source multilingual ner dataset from the provided sample.\": 1,\n",
       "  'masakhane ner dataset': 3,\n",
       "  \"sorry, but i can't provide the exact source of this multilingual ner (named entity recognition) dataset based on the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific source of a multilingual ner (named entity recognition) dataset from a single sentence or phrase.\": 1,\n",
       "  \"i'm sorry, but without additional context, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source multilingual ner (named entity recognition) dataset for the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample comes from.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset this sample is from.\": 1,\n",
       "  'wikiann': 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from the provided sample.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the specific multilingual ner (named entity recognition) dataset from which this sample is taken.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset.\": 1,\n",
       "  \"i'm sorry, but the provided text doesn't seem to be a part of a well-known multilingual ner (named entity recognition) dataset. it's also important to note that without additional context or metadata, it's challenging to accurately identify the source dataset of a given text sample.\": 1,\n",
       "  \"sorry, but the provided sample doesn't contain enough information to identify a specific multilingual ner (named entity recognition) dataset.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify the source of this multilingual ner (named entity recognition) dataset from the provided sample alone.\": 1,\n",
       "  'masakhane ner corpus': 1,\n",
       "  \"i'm sorry, but it's not possible to identify the source multilingual ner (named entity recognition) dataset from this sample alone. the text appears to be in chichewa, a language spoken in malawi, but without more context or information, it's not possible to identify a specific dataset.\": 1,\n",
       "  \"i'm sorry, but without additional context or information, it's not possible to identify a specific multilingual ner (named entity recognition) dataset from this text sample alone.\": 1}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate number of times the data sample source was guessed correctly\n",
    "masakhaner2_answers = json.load(open(os.path.join(RESULTS_PATH, f'masakhaner2_sample_source.json'), 'r'))\n",
    "\n",
    "# Count number of times each dataset name is predicted\n",
    "masakhaner2_counts = []\n",
    "\n",
    "for experiment_i in tqdm(range(repeat_experiment), desc=\"Experiment #\"):\n",
    "    masakhaner2_answers_list = []\n",
    "\n",
    "    experiment_answers = masakhaner2_answers[experiment_i]\n",
    "    for split, samples in experiment_answers.items():\n",
    "        masakhaner2_answers_list += list(samples.values())\n",
    "\n",
    "    # Append current experiment answers\n",
    "    masakhaner2_counts.append(dict(Counter(masakhaner2_answers_list)))\n",
    "\n",
    "masakhaner2_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abaca3cf05c7c01c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:23:42.062958Z",
     "start_time": "2024-03-06T20:23:42.058598Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Std: 0.0\n"
     ]
    }
   ],
   "source": [
    "mean, std = compute_guess_stats(answers=masakhaner2_counts, pattern=re.compile(r'masakhaner 2.0'))\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2dca894790fb450a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:23:27.429899Z",
     "start_time": "2024-03-06T20:23:27.424101Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.42\n",
      "Std: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of times the data sample source was guessed incorrectly\n",
    "mean, std = compute_guess_stats(answers=masakhaner2_counts, \n",
    "                                pattern=re.compile(r'(masakhanener ?$|masakhaner ?$|masakhane ner)'))\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce3fa843b0cbba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Asking the model to continue sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3beba71f2b7b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Following the approach suggested here: https://arxiv.org/abs/2308.08493"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688df8d18329985",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CoNLL-2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3ddf83441c59863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:34.604294Z",
     "start_time": "2024-03-06T20:19:33.241809Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll = load_dataset(\"conll2003\")\n",
    "conll_samples = sample_from_dataset(conll, num_samples=10)['train']\n",
    "conll_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f05fc497a7877e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:42.290238Z",
     "start_time": "2024-03-06T20:19:34.605533Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ba637d417047b8aeb08e6d27d3955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "results = {}\n",
    "\n",
    "for id_, tokens in tqdm(zip(conll_samples['id'], conll_samples['tokens']), total=10):\n",
    "    results[id_] = {}\n",
    "    \n",
    "    # Cut-off - at least 2 tokens at the beginning\n",
    "    cut_off = int(np.ceil(len(tokens)/2))\n",
    "\n",
    "    query_text = ' '.join(tokens[:cut_off])\n",
    "    reference_text = ' '.join(tokens[cut_off:])\n",
    "    \n",
    "    user_prompt = GUI_SENT.format(\n",
    "        split_name='train', \n",
    "        dataset_name='CoNLL-2003',\n",
    "        sentence=query_text\n",
    "    )\n",
    "     \n",
    "    answer = ask_gpt(user_prompt, **ASK_GPT_PARAMS)\n",
    "\n",
    "    results[id_]['query_text'] = query_text\n",
    "    results[id_]['reference_text'] = reference_text\n",
    "    results[id_]['answer'] = answer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a17efdf617e4a785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:42.294702Z",
     "start_time": "2024-03-06T20:19:42.291474Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'CoNLL-2003_sentence_continuation.json'), 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77d4ecce8668d1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:42.298665Z",
     "start_time": "2024-03-06T20:19:42.295689Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = json.load(open(os.path.join(RESULTS_PATH, f'CoNLL-2003_sentence_continuation.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca4e27f1952205ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:42.313914Z",
     "start_time": "2024-03-06T20:19:42.299671Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0d6fc65b5145e69de7b501cb7c0d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Start of the sentence:\n",
      " Attendance :\n",
      "--> Reference (ground truth):\n",
      "1,800\n",
      "--> Model's prediction:\n",
      "at the meeting was compulsory .\n",
      "\n",
      "--> Start of the sentence:\n",
      " Ties between the two neighbours , strained also over a military accord between Turkey and Israel which drew strong\n",
      "--> Reference (ground truth):\n",
      "Iranian objections , have improved since Islamist Necmettin Erbakan took over as Turkish prime minister in June .\n",
      "--> Model's prediction:\n",
      "criticism from Iran , have been further complicated by the dispute .\n",
      "\n",
      "--> Start of the sentence:\n",
      " The winner has to secure a majority from the college within two rounds\n",
      "--> Reference (ground truth):\n",
      "of voting otherwise the election will go back before the parliament .\n",
      "--> Model's prediction:\n",
      "of voting . If no candidate secures a majority , the two with the most votes go into a third round .\n",
      "\n",
      "--> Start of the sentence:\n",
      " LIBERIA , Costa\n",
      "--> Reference (ground truth):\n",
      "Rica 1996-08-26\n",
      "--> Model's prediction:\n",
      "Rica - 1\n",
      "\n",
      "--> Start of the sentence:\n",
      " 1. Sorensen\n",
      "--> Reference (ground truth):\n",
      "11.20:33\n",
      "--> Model's prediction:\n",
      ", who is 47 , was appointed as vice president of the company in 1990 .\n",
      "\n",
      "--> Start of the sentence:\n",
      " 9. Akira Ryo (\n",
      "--> Reference (ground truth):\n",
      "Japan ) Kawasaki 38:50.269\n",
      "--> Model's prediction:\n",
      "Suzuki )\n",
      "\n",
      "--> Start of the sentence:\n",
      " Six months to September\n",
      "--> Reference (ground truth):\n",
      "30 , 1996\n",
      "--> Model's prediction:\n",
      "30 , 1996 , the Company\n",
      "\n",
      "--> Start of the sentence:\n",
      " P1020 ingot 75\n",
      "--> Reference (ground truth):\n",
      "cents / pound\n",
      "--> Model's prediction:\n",
      "mm thick .\n",
      "\n",
      "--> Start of the sentence:\n",
      " Sale Amount\n",
      "--> Reference (ground truth):\n",
      ": 4,300,000\n",
      "--> Model's prediction:\n",
      ": 12.5 million pounds\n",
      "\n",
      "--> Start of the sentence:\n",
      " The use of riverways in the region has been made a priority under a government plan for the Amazon\n",
      "--> Reference (ground truth):\n",
      "and the high-speed hovercraft will help reduce the time involved in travelling often massive distances , it said .\n",
      "--> Model's prediction:\n",
      ", which aims to develop local economies without causing environmental damage .\n"
     ]
    }
   ],
   "source": [
    "for id_, results_dict in tqdm(results.items()):\n",
    "    print('--> Start of the sentence:\\n', results_dict['query_text'])\n",
    "    print(\"--> Reference (ground truth):\")\n",
    "    print(results_dict['reference_text'])\n",
    "    print(\"--> Model's prediction:\")\n",
    "    print(results_dict['answer'])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8286a9561c2c36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:47.879941Z",
     "start_time": "2024-03-06T20:19:42.315249Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b34c0a04634fb9bce3f65ae81a4018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'No': 10})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_arr = []\n",
    "\n",
    "for id_, results_dict in tqdm(results.items(), total=10):\n",
    "    \n",
    "    user_prompt = ICL_EVAL.format(\n",
    "        reference_text=results_dict['reference_text'],\n",
    "        candidate_text=results_dict['answer']\n",
    "    )\n",
    "    answer = ask_gpt(user_prompt, openai_client, temperature=TEMPERATURE, model='gpt-4')\n",
    "    results[id_]['match'] = answer\n",
    "\n",
    "    match_arr.append(answer)\n",
    "    \n",
    "Counter(match_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd9947c242927c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### WikiANN (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b92a76c0831e6dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:19:48.175670Z",
     "start_time": "2024-03-06T20:19:47.881008Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get languages from the dataset\n",
    "url = \"https://datasets-server.huggingface.co/splits?dataset=wikiann\"\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "wikiann_languages = sorted(list({item['config'] for item in data['splits']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c894b5fc52bcada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:20.956282Z",
     "start_time": "2024-03-06T20:19:48.176649Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d21588dddf4db6aade10b3ddd2c5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/ace (download: 33.18 KiB, generated: 79.23 KiB, post-processed: Unknown size, total: 112.40 KiB) to /root/.cache/huggingface/datasets/parquet/ace-c175dd3637ea0c5e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c175dd3637ea0c5e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Klimop ( Ôostkamp )\n",
      "Downloading and preparing dataset None/ace (download: 26.40 KiB, generated: 66.69 KiB, post-processed: Unknown size, total: 93.09 KiB) to /root/.cache/huggingface/datasets/parquet/ace-9f12e683d0704dd7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-9f12e683d0704dd7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Noruwega nag-angkon sa maong dapit .\n",
      "Downloading and preparing dataset None/ace (download: 2.46 MiB, generated: 8.93 MiB, post-processed: Unknown size, total: 11.39 MiB) to /root/.cache/huggingface/datasets/parquet/ace-f6d90983d029509f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-f6d90983d029509f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "روبرت دي نيرو 2\n",
      "Downloading and preparing dataset None/ace (download: 2.10 MiB, generated: 7.29 MiB, post-processed: Unknown size, total: 9.39 MiB) to /root/.cache/huggingface/datasets/parquet/ace-38ff742c0b31abe7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-38ff742c0b31abe7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Kabupaten Manggarai ( 14-09-2015 ) ,\n",
      "Downloading and preparing dataset None/ace (download: 27.19 KiB, generated: 51.21 KiB, post-processed: Unknown size, total: 78.40 KiB) to /root/.cache/huggingface/datasets/parquet/ace-c71fce17ed8efad3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c71fce17ed8efad3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Â-lî-sân Koet-kâ Sêm-lìm Yù-lo̍k-khî\n",
      "Downloading and preparing dataset None/ace (download: 27.93 KiB, generated: 44.78 KiB, post-processed: Unknown size, total: 72.71 KiB) to /root/.cache/huggingface/datasets/parquet/ace-ef5bb871b53b8cd7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-ef5bb871b53b8cd7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "' '' 艮自侯 站 '' '（Gants 倫敦地鐵嗰\n",
      "Downloading and preparing dataset None/ace (download: 615.86 KiB, generated: 2.68 MiB, post-processed: Unknown size, total: 3.28 MiB) to /root/.cache/huggingface/datasets/parquet/ace-e7b8ceeb4277a560/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-e7b8ceeb4277a560/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Taith Bryn Euryn .\n",
      "Downloading and preparing dataset None/ace (download: 34.18 KiB, generated: 105.85 KiB, post-processed: Unknown size, total: 140.03 KiB) to /root/.cache/huggingface/datasets/parquet/ace-77356950b3ab7c3d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-77356950b3ab7c3d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Lièng-hăk-guók : Dṳ̆ng-ùng Ngṳ̄-ngiòng Nĭk\n",
      "Downloading and preparing dataset None/ace (download: 31.20 KiB, generated: 178.44 KiB, post-processed: Unknown size, total: 209.63 KiB) to /root/.cache/huggingface/datasets/parquet/ace-92d965d1be82c0fc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-92d965d1be82c0fc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "一 ︰ 紐 約 市 ；\n",
      "Downloading and preparing dataset None/ace (download: 2.81 MiB, generated: 8.98 MiB, post-processed: Unknown size, total: 11.79 MiB) to /root/.cache/huggingface/datasets/parquet/ace-c4e351a8849ca20f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-c4e351a8849ca20f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "Do seniorského mužstva FC Nitra sa dostal ako 18 ročný .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vls': {'query_text': 'Klimop (',\n",
       "  'reference_text': 'Ôostkamp )',\n",
       "  'answer': 'Hedera)'},\n",
       " 'ceb': {'query_text': 'Noruwega nag-angkon sa',\n",
       "  'reference_text': 'maong dapit .',\n",
       "  'answer': 'iyanhong mga teritoryo.'},\n",
       " 'ar': {'query_text': 'روبرت دي',\n",
       "  'reference_text': 'نيرو 2',\n",
       "  'answer': 'نيرو'},\n",
       " 'id': {'query_text': 'Kabupaten Manggarai (',\n",
       "  'reference_text': '14-09-2015 ) ,',\n",
       "  'answer': 'Indonesian: Kabupaten Manggarai) is a regency in East Nusa Tenggara province of Indonesia.'},\n",
       " 'hak': {'query_text': 'Â-lî-sân Koet-kâ',\n",
       "  'reference_text': 'Sêm-lìm Yù-lo̍k-khî',\n",
       "  'answer': 'is a Taiwanese Hokkien television series.'},\n",
       " 'gan': {'query_text': \"' '' 艮自侯 站\",\n",
       "  'reference_text': \"'' '（Gants 倫敦地鐵嗰\",\n",
       "  'answer': \"'' 艮自侯 站 是 中国铁路哈尔滨局集团有限公司 下属的一个车站，位于中国黑龙江省哈尔滨市道里区，成立于 1903年，车站等级为四等站。\"},\n",
       " 'cy': {'query_text': 'Taith Bryn',\n",
       "  'reference_text': 'Euryn .',\n",
       "  'answer': 'Terfel yn America'},\n",
       " 'cdo': {'query_text': 'Lièng-hăk-guók : Dṳ̆ng-ùng',\n",
       "  'reference_text': 'Ngṳ̄-ngiòng Nĭk',\n",
       "  'answer': 'Lièng-hăk-guók : Dṳ̆ng-ùng'},\n",
       " 'zh-classical': {'query_text': '一 ︰ 紐',\n",
       "  'reference_text': '約 市 ；',\n",
       "  'answer': '約 是 美國 的 一 個 州 ， 位 於 東 北 部 ， 由 長 島 、 曼 哈 頓 、 斯 塔 登 島 、 布 魯 克 林 和 皇 后 區 組 成 ， 是 美國 最 大 的 城 市 ， 也 是 全 球 最 重 要 的 經 濟 、 金 融 和 文 化 中 心 之 一 。'},\n",
       " 'sk': {'query_text': 'Do seniorského mužstva FC Nitra sa',\n",
       "  'reference_text': 'dostal ako 18 ročný .',\n",
       "  'answer': 'vrátil v roku 2006.'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "results = {}\n",
    "\n",
    "# Disable datasets load_dataset progress bar\n",
    "disable_progress_bar()\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    seed = 0\n",
    "    random_language = random.choice(wikiann_languages)\n",
    "\n",
    "    wikiann = load_dataset(\"wikiann\", data_dir=random_language,\n",
    "                           download_mode=\"force_redownload\",\n",
    "                           verification_mode=\"no_checks\")\n",
    "\n",
    "    wikiann_samples = sample_from_dataset(wikiann, num_samples=1, seed=seed)['train']\n",
    "    \n",
    "    while len(wikiann_samples['tokens'][0]) <= 2:\n",
    "        seed += 1\n",
    "        wikiann_samples = sample_from_dataset(wikiann, num_samples=1, seed=seed)['train']\n",
    "        \n",
    "    tokens = wikiann_samples['tokens'][0]\n",
    "\n",
    "    results[random_language] = {}\n",
    "\n",
    "    # Cut-off - at least 2 tokens at the beginning\n",
    "    cut_off = int(np.ceil(len(tokens)/2))\n",
    "\n",
    "    query_text = ' '.join(tokens[:cut_off])\n",
    "    reference_text = ' '.join(tokens[cut_off:])\n",
    "    print(query_text, reference_text)\n",
    "\n",
    "    user_prompt = GUI_SENT.format(\n",
    "        split_name='train',\n",
    "        dataset_name='WikiAnn',\n",
    "        sentence=query_text\n",
    "    )\n",
    "\n",
    "    answer = ask_gpt(user_prompt, **ASK_GPT_PARAMS)\n",
    "\n",
    "    results[random_language]['query_text'] = query_text\n",
    "    results[random_language]['reference_text'] = reference_text\n",
    "    results[random_language]['answer'] = answer\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1cc3e726ecd69fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:20.962214Z",
     "start_time": "2024-03-06T20:21:20.958148Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'WikiAnn_sentence_continuation.json'), 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92815494729e9b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:20.976889Z",
     "start_time": "2024-03-06T20:21:20.963748Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = json.load(open(os.path.join(RESULTS_PATH, f'WikiAnn_sentence_continuation.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "494f4b667d6c5328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:26.443932Z",
     "start_time": "2024-03-06T20:21:20.978615Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420b05e346b34382826dfe6724f4d03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'No': 10})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_arr = []\n",
    "\n",
    "for id_, results_dict in tqdm(results.items(), total=10):\n",
    "\n",
    "    user_prompt = ICL_EVAL.format(\n",
    "        reference_text=results_dict['reference_text'],\n",
    "        candidate_text=results_dict['answer']\n",
    "    )\n",
    "    answer = ask_gpt(user_prompt, openai_client, temperature=TEMPERATURE, model='gpt-4')\n",
    "    results[id_]['match'] = answer\n",
    "\n",
    "    match_arr.append(answer)\n",
    "\n",
    "Counter(match_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883bd77252a2b20e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### WikiANN (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ec4f63d05cc4e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:35.017196Z",
     "start_time": "2024-03-06T20:21:26.444952Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/ace (download: 2.85 MiB, generated: 8.92 MiB, post-processed: Unknown size, total: 11.78 MiB) to /root/.cache/huggingface/datasets/parquet/ace-ea28d0999d5d2e61/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/ace-ea28d0999d5d2e61/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiann = load_dataset(\"wikiann\", data_dir='en',\n",
    "                       download_mode=\"force_redownload\",\n",
    "                       verification_mode=\"no_checks\")\n",
    "wikiann_samples = sample_from_dataset(wikiann, num_samples=10)['train']\n",
    "wikiann_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4236fbe3ad5c6578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:44.656525Z",
     "start_time": "2024-03-06T20:21:35.018763Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f2bb82402143838b6e6c30423bc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "results = {}\n",
    "\n",
    "for id_, tokens in tqdm(enumerate(wikiann_samples['tokens']), total=10):\n",
    "    results[id_] = {}\n",
    "\n",
    "    # Cut-off - at least 2 tokens at the beginning\n",
    "    cut_off = int(np.ceil(len(tokens)/2))\n",
    "\n",
    "    query_text = ' '.join(tokens[:cut_off])\n",
    "    reference_text = ' '.join(tokens[cut_off:])\n",
    "\n",
    "    user_prompt = GUI_SENT.format(\n",
    "        split_name='train',\n",
    "        dataset_name='WikiAnn',\n",
    "        sentence=query_text\n",
    "    )\n",
    "\n",
    "    answer = ask_gpt(user_prompt, **ASK_GPT_PARAMS)\n",
    "\n",
    "    results[id_]['query_text'] = query_text\n",
    "    results[id_]['reference_text'] = reference_text\n",
    "    results[id_]['answer'] = answer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6e13d41fddf6790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:44.661969Z",
     "start_time": "2024-03-06T20:21:44.658249Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'WikiAnn_eng_sentence_continuation.json'), 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a4534bbb0b7949a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:44.665788Z",
     "start_time": "2024-03-06T20:21:44.662956Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = json.load(open(os.path.join(RESULTS_PATH, f'WikiAnn_eng_sentence_continuation.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cb134510b41e774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:44.676745Z",
     "start_time": "2024-03-06T20:21:44.666599Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51856a61718249719dab92725c45d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Start of the sentence:\n",
      " Stratford ,\n",
      "--> Reference (ground truth):\n",
      "Oklahoma\n",
      "--> Model's prediction:\n",
      "Ontario\n",
      "\n",
      "--> Start of the sentence:\n",
      " Anders Behring\n",
      "--> Reference (ground truth):\n",
      "Breivik\n",
      "--> Model's prediction:\n",
      "Breivik\n",
      "\n",
      "--> Start of the sentence:\n",
      " '' The World as Best as I Remember\n",
      "--> Reference (ground truth):\n",
      "It , Volume Two '' ( 1992 )\n",
      "--> Model's prediction:\n",
      "It '' is a memoir by Canadian author and broadcaster Stuart McLean.\n",
      "\n",
      "--> Start of the sentence:\n",
      " 24 Apr –\n",
      "--> Reference (ground truth):\n",
      "Heinrich Himmler\n",
      "--> Model's prediction:\n",
      "2005 - The first ever video is uploaded to YouTube.\n",
      "\n",
      "--> Start of the sentence:\n",
      " `` Flight of Icarus ''\n",
      "--> Reference (ground truth):\n",
      "( Tierra Santa )\n",
      "--> Model's prediction:\n",
      "is a song by the English heavy metal band Iron Maiden. It was their eighth single, the first from their fourth studio album, Piece of Mind, and their first in the United States, where it was one of their few with substantial airplay, peaking at No. 8 in the Mainstream Rock chart. It was a lesser success in the UK, peaking at No. 11 in the UK Singles Chart.\n",
      "\n",
      "--> Start of the sentence:\n",
      " Bath and North\n",
      "--> Reference (ground truth):\n",
      "East Somerset\n",
      "--> Model's prediction:\n",
      "East Somerset\n",
      "\n",
      "--> Start of the sentence:\n",
      " Communes of the\n",
      "--> Reference (ground truth):\n",
      "Marne department\n",
      "--> Model's prediction:\n",
      "Ain department\n",
      "\n",
      "--> Start of the sentence:\n",
      " 1970 — did\n",
      "--> Reference (ground truth):\n",
      "not compete\n",
      "--> Model's prediction:\n",
      "not compete\n",
      "\n",
      "--> Start of the sentence:\n",
      " In Djibouti city , for instance , average\n",
      "--> Reference (ground truth):\n",
      "afternoon highs range from in April .\n",
      "--> Model's prediction:\n",
      "temperatures range from 27 to 33 degrees Celsius.\n",
      "\n",
      "--> Start of the sentence:\n",
      " Prince Valdemar\n",
      "--> Reference (ground truth):\n",
      "of Denmark\n",
      "--> Model's prediction:\n",
      "of Denmark\n"
     ]
    }
   ],
   "source": [
    "for id_, results_dict in tqdm(results.items()):\n",
    "    print('--> Start of the sentence:\\n', results_dict['query_text'])\n",
    "    print(\"--> Reference (ground truth):\")\n",
    "    print(results_dict['reference_text'])\n",
    "    print(\"--> Model's prediction:\")\n",
    "    print(results_dict['answer'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5aed97f4f4a1cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:50.975327Z",
     "start_time": "2024-03-06T20:21:44.677567Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5541ac9c71849beafd6aee89fc0b49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'No': 6, 'Yes (exact match)': 4})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_arr = []\n",
    "\n",
    "for id_, results_dict in tqdm(results.items(), total=10):\n",
    "\n",
    "    user_prompt = ICL_EVAL.format(\n",
    "        reference_text=results_dict['reference_text'],\n",
    "        candidate_text=results_dict['answer']\n",
    "    )\n",
    "    answer = ask_gpt(user_prompt, openai_client, temperature=TEMPERATURE, model='gpt-4')\n",
    "    results[id_]['match'] = answer\n",
    "\n",
    "    match_arr.append(answer)\n",
    "\n",
    "Counter(match_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3544edf7d4bdf89",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### masakhaner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32289432d769bb81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:50.979793Z",
     "start_time": "2024-03-06T20:21:50.976910Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Languages that were added to the second version of the masakhaner2\n",
    "masakhaner2_languages = ['bam', 'ewe', 'fon', 'twi', 'bbj', 'nya', 'tsn', 'sna', 'xho', 'zul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d6f41cc2201135a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:21:50.982951Z",
     "start_time": "2024-03-06T20:21:50.980642Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GUI_SENT = \"\"\"INSTRUCTION:\n",
    "You are provided with the FIRST PIECE of data sample tokens in {language} from the {split_name} split of the {dataset_name} dataset. Finish the SECOND PIECE of the sample tokens as EXACTLY appeared in the dataset. ONLY rely on the original form of the sample tokens in the dataset to finish the SECOND PIECE. Do not return labels, provide only tokens exactly as they appear in the dataset.\n",
    "\n",
    "FIRST PIECE:\n",
    "{sentence}\n",
    "\n",
    "SECOND PIECE:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e229ad6cd1651607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:22:19.414905Z",
     "start_time": "2024-03-06T20:21:50.983776Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998225c3974b4cf4aa00ddf9a2cd3363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaʋaladzinɔnɔ naa be mieŋlɔa mia amedzesiwo be .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/bam/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEYE perezidan an'a Sekeretɛri zenerali ka ladilikanw fɛ , laɲini yɛlɛmana k'a kɛ Bolofara Lajɛ balalen dɔ de kɔni ɲinini ye , min bɛna laban ne binni na .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/bbj/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philémon Yang biŋ cə́ŋtə́ ntútə́ púa mtiŋ myə ǎ bɔ dá'tə gaə́ dyə̂fa' Ntwɔ́kshwɛ Atou dzʉ́ pè nə̂ mu' pə́púŋ tə a bó dɔ́ .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/twi/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɔmanpanin Akufo - Addo se , ɔbɛyɛ deɛ ɔbɛtumi biara de asi galamsey ano ansa na ne berɛ a ɛtɔ so mmienu no atwam ɔpɛpɔn , 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/twi/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amnyɔkuo no panyin , Nelson ɔhamisa , aka sɛ ɔbɛkɔ so ako ama nsesa aba ɔman no mu ɛmfa ho ne nnipa binom a wɔkye wɔn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/fon/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kplékplé gbɛ̀tà gbɛ ɔ́ tɔn , sɔ́ azǎn mɔ̀ nyínkɔ́ tɔn ɖó é kplé xá Jeux Olimpique Modernes è blǒ ɖo azǎn 06ɔ́ lidòsùn xwè 1896ɔ́ tɔn è blǒ ɖo Athènes èe wú .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esi wonye be yeƒe hatruiawoe nana wolena , de , = = nu ŋuti la esia kpe ɖe eŋu wogale amewo lem .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/xho/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kwaba bantu babhubhileyo , amashumi amathandathu anesithandathu ( 66 ) kubo ngabantwana .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/ewe/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journée FIFA : Guinée ƒe afɔbɔlƒolawo wɔ dɔgbegbenɔnɔme kuɖe woƒe tamega aɖewo ƒe matumatu ŋuti .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner2 (/root/.cache/huggingface/datasets/masakhane___masakhaner2/zul/1.0.0/f5700a8b1468e7e03e17fe87897dca01d2eb8db3f67de132ada8396091a42963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okukhulu kunakho konke uMotsepe akufunayo , ukuqala kokusetshenziswa kwemishini ye - Video Assistant Referee ( VAR ) .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'query_text': 'Yaʋaladzinɔnɔ naa be mieŋlɔa',\n",
       "  'reference_text': 'mia amedzesiwo be .',\n",
       "  'answer': 'woe la, ɖe amesiame me.'},\n",
       " 1: {'query_text': \"SEYE perezidan an'a Sekeretɛri zenerali ka ladilikanw fɛ , laɲini yɛlɛmana k'a kɛ Bolofara Lajɛ\",\n",
       "  'reference_text': 'balalen dɔ de kɔni ɲinini ye , min bɛna laban ne binni na .',\n",
       "  'answer': 'kɛnɛya.'},\n",
       " 2: {'query_text': \"Philémon Yang biŋ cə́ŋtə́ ntútə́ púa mtiŋ myə ǎ bɔ dá'tə gaə́ dyə̂fa'\",\n",
       "  'reference_text': \"Ntwɔ́kshwɛ Atou dzʉ́ pè nə̂ mu' pə́púŋ tə a bó dɔ́ .\",\n",
       "  'answer': \"ǎ bɔ dá'tə gaə́ dyə̂fa' ǎ bɔ dá'tə gaə́ dyə̂fa' ǎ bɔ dá'tə gaə́ dyə̂fa'\"},\n",
       " 3: {'query_text': 'ɔmanpanin Akufo - Addo se , ɔbɛyɛ deɛ ɔbɛtumi biara de asi galamsey ano',\n",
       "  'reference_text': 'ansa na ne berɛ a ɛtɔ so mmienu no atwam ɔpɛpɔn , 2015',\n",
       "  'answer': 'mu .'},\n",
       " 4: {'query_text': 'Amnyɔkuo no panyin , Nelson ɔhamisa , aka sɛ ɔbɛkɔ so ako ama',\n",
       "  'reference_text': 'nsesa aba ɔman no mu ɛmfa ho ne nnipa binom a wɔkye wɔn',\n",
       "  'answer': 'ɔbɛtumi akyerɛ wɔn sɛnea ɛbɛyɛ a wɔbɛtumi akyerɛ wɔn.'},\n",
       " 5: {'query_text': 'Kplékplé gbɛ̀tà gbɛ ɔ́ tɔn , sɔ́ azǎn mɔ̀ nyínkɔ́ tɔn ɖó é kplé xá Jeux Olimpique',\n",
       "  'reference_text': 'Modernes è blǒ ɖo azǎn 06ɔ́ lidòsùn xwè 1896ɔ́ tɔn è blǒ ɖo Athènes èe wú .',\n",
       "  'answer': 'ɖɔ́ ɖó é kplé xá 2008 nú Pékin .'},\n",
       " 6: {'query_text': 'Esi wonye be yeƒe hatruiawoe nana wolena , de , = =',\n",
       "  'reference_text': 'nu ŋuti la esia kpe ɖe eŋu wogale amewo lem .',\n",
       "  'answer': 'woe be yeƒe hatruiawoe nana wolena , de , = ='},\n",
       " 7: {'query_text': 'Kwaba bantu babhubhileyo , amashumi amathandathu anesithandathu',\n",
       "  'reference_text': '( 66 ) kubo ngabantwana .',\n",
       "  'answer': 'ababini ababhubhileyo , amashumi amabini anesithandathu ababhubhileyo .'},\n",
       " 8: {'query_text': 'Journée FIFA : Guinée ƒe afɔbɔlƒolawo wɔ dɔgbegbenɔnɔme',\n",
       "  'reference_text': 'kuɖe woƒe tamega aɖewo ƒe matumatu ŋuti .',\n",
       "  'answer': 'me ƒe Togo ƒe afɔbɔlƒolawo wɔ dɔgbegbenɔnɔme.'},\n",
       " 9: {'query_text': 'Okukhulu kunakho konke uMotsepe akufunayo , ukuqala kokusetshenziswa kwemishini',\n",
       "  'reference_text': 'ye - Video Assistant Referee ( VAR ) .',\n",
       "  'answer': 'yokugcina imvelo kanye nokunciphisa ukungcola kwemvelo .'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "results = {}\n",
    "\n",
    "\n",
    "# Disable datasets load_dataset progress bar\n",
    "disable_progress_bar()\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    seed = 0\n",
    "    random_language = random.choice(masakhaner2_languages)\n",
    "\n",
    "    masaknaner2 = load_dataset(config['dataset'], random_language)\n",
    "\n",
    "    masaknaner2_samples = sample_from_dataset(masaknaner2, num_samples=1, seed=i)['train']\n",
    "\n",
    "    while len(masaknaner2_samples['tokens'][0]) <= 2:\n",
    "        seed *= 100\n",
    "        masaknaner2_samples = sample_from_dataset(masaknaner2, num_samples=1, seed=seed)['train']\n",
    "\n",
    "    tokens = masaknaner2_samples['tokens'][0]\n",
    "\n",
    "    results[i] = {}\n",
    "\n",
    "    # Cut-off - at least 2 tokens at the beginning\n",
    "    cut_off = int(np.ceil(len(tokens)/2))\n",
    "\n",
    "    query_text = ' '.join(tokens[:cut_off])\n",
    "    reference_text = ' '.join(tokens[cut_off:])\n",
    "    print(query_text, reference_text)\n",
    "\n",
    "    user_prompt = GUI_SENT.format(\n",
    "        split_name='train',\n",
    "        dataset_name='MasakhaNER 2.0',\n",
    "        sentence=query_text,\n",
    "        language=config['languages_names'][random_language]\n",
    "    )\n",
    "\n",
    "    answer = ask_gpt(user_prompt, **ASK_GPT_PARAMS)\n",
    "\n",
    "    results[i]['query_text'] = query_text\n",
    "    results[i]['reference_text'] = reference_text\n",
    "    results[i]['answer'] = answer\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97a3b6251b878f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:22:19.421586Z",
     "start_time": "2024-03-06T20:22:19.416429Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, f'masakhaner2_sentence_continuation.json'), 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1356cf599f2a0635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:22:19.426092Z",
     "start_time": "2024-03-06T20:22:19.422600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = json.load(open(os.path.join(RESULTS_PATH, f'masakhaner2_sentence_continuation.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a6d78a6c2dccb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:22:19.443201Z",
     "start_time": "2024-03-06T20:22:19.427359Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77f28528e304b309a7e859b0be2dfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Start of the sentence:\n",
      " Yaʋaladzinɔnɔ naa be mieŋlɔa\n",
      "--> Reference (ground truth):\n",
      "mia amedzesiwo be .\n",
      "--> Model's prediction:\n",
      "woe la, ɖe amesiame me.\n",
      "\n",
      "--> Start of the sentence:\n",
      " SEYE perezidan an'a Sekeretɛri zenerali ka ladilikanw fɛ , laɲini yɛlɛmana k'a kɛ Bolofara Lajɛ\n",
      "--> Reference (ground truth):\n",
      "balalen dɔ de kɔni ɲinini ye , min bɛna laban ne binni na .\n",
      "--> Model's prediction:\n",
      "kɛnɛya.\n",
      "\n",
      "--> Start of the sentence:\n",
      " Philémon Yang biŋ cə́ŋtə́ ntútə́ púa mtiŋ myə ǎ bɔ dá'tə gaə́ dyə̂fa'\n",
      "--> Reference (ground truth):\n",
      "Ntwɔ́kshwɛ Atou dzʉ́ pè nə̂ mu' pə́púŋ tə a bó dɔ́ .\n",
      "--> Model's prediction:\n",
      "ǎ bɔ dá'tə gaə́ dyə̂fa' ǎ bɔ dá'tə gaə́ dyə̂fa' ǎ bɔ dá'tə gaə́ dyə̂fa'\n",
      "\n",
      "--> Start of the sentence:\n",
      " ɔmanpanin Akufo - Addo se , ɔbɛyɛ deɛ ɔbɛtumi biara de asi galamsey ano\n",
      "--> Reference (ground truth):\n",
      "ansa na ne berɛ a ɛtɔ so mmienu no atwam ɔpɛpɔn , 2015\n",
      "--> Model's prediction:\n",
      "mu .\n",
      "\n",
      "--> Start of the sentence:\n",
      " Amnyɔkuo no panyin , Nelson ɔhamisa , aka sɛ ɔbɛkɔ so ako ama\n",
      "--> Reference (ground truth):\n",
      "nsesa aba ɔman no mu ɛmfa ho ne nnipa binom a wɔkye wɔn\n",
      "--> Model's prediction:\n",
      "ɔbɛtumi akyerɛ wɔn sɛnea ɛbɛyɛ a wɔbɛtumi akyerɛ wɔn.\n",
      "\n",
      "--> Start of the sentence:\n",
      " Kplékplé gbɛ̀tà gbɛ ɔ́ tɔn , sɔ́ azǎn mɔ̀ nyínkɔ́ tɔn ɖó é kplé xá Jeux Olimpique\n",
      "--> Reference (ground truth):\n",
      "Modernes è blǒ ɖo azǎn 06ɔ́ lidòsùn xwè 1896ɔ́ tɔn è blǒ ɖo Athènes èe wú .\n",
      "--> Model's prediction:\n",
      "ɖɔ́ ɖó é kplé xá 2008 nú Pékin .\n",
      "\n",
      "--> Start of the sentence:\n",
      " Esi wonye be yeƒe hatruiawoe nana wolena , de , = =\n",
      "--> Reference (ground truth):\n",
      "nu ŋuti la esia kpe ɖe eŋu wogale amewo lem .\n",
      "--> Model's prediction:\n",
      "woe be yeƒe hatruiawoe nana wolena , de , = =\n",
      "\n",
      "--> Start of the sentence:\n",
      " Kwaba bantu babhubhileyo , amashumi amathandathu anesithandathu\n",
      "--> Reference (ground truth):\n",
      "( 66 ) kubo ngabantwana .\n",
      "--> Model's prediction:\n",
      "ababini ababhubhileyo , amashumi amabini anesithandathu ababhubhileyo .\n",
      "\n",
      "--> Start of the sentence:\n",
      " Journée FIFA : Guinée ƒe afɔbɔlƒolawo wɔ dɔgbegbenɔnɔme\n",
      "--> Reference (ground truth):\n",
      "kuɖe woƒe tamega aɖewo ƒe matumatu ŋuti .\n",
      "--> Model's prediction:\n",
      "me ƒe Togo ƒe afɔbɔlƒolawo wɔ dɔgbegbenɔnɔme.\n",
      "\n",
      "--> Start of the sentence:\n",
      " Okukhulu kunakho konke uMotsepe akufunayo , ukuqala kokusetshenziswa kwemishini\n",
      "--> Reference (ground truth):\n",
      "ye - Video Assistant Referee ( VAR ) .\n",
      "--> Model's prediction:\n",
      "yokugcina imvelo kanye nokunciphisa ukungcola kwemvelo .\n"
     ]
    }
   ],
   "source": [
    "for id_, results_dict in tqdm(results.items()):\n",
    "    print('--> Start of the sentence:\\n', results_dict['query_text'])\n",
    "    print(\"--> Reference (ground truth):\")\n",
    "    print(results_dict['reference_text'])\n",
    "    print(\"--> Model's prediction:\")\n",
    "    print(results_dict['answer'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eebaeb9e913ca816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:22:25.290991Z",
     "start_time": "2024-03-06T20:22:19.444223Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec87e0d635a41d593e8a55ac5a6bc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'No': 10})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_arr = []\n",
    "\n",
    "for id_, results_dict in tqdm(results.items(), total=10):\n",
    "\n",
    "    user_prompt = ICL_EVAL.format(\n",
    "        reference_text=results_dict['reference_text'],\n",
    "        candidate_text=results_dict['answer']\n",
    "    )\n",
    "    answer = ask_gpt(user_prompt, openai_client, temperature=TEMPERATURE, model='gpt-4')\n",
    "    results[id_]['match'] = answer\n",
    "\n",
    "    match_arr.append(answer)\n",
    "\n",
    "Counter(match_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
